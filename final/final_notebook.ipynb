{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_exploration import *\n",
    "from final_modeling import *\n",
    "\n",
    "\n",
    "alpha=0.05\n",
    "target='logerror'\n",
    "\n",
    "\n",
    "random.seed(123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "partitionslist=partitionslist_with_scaled(scaled_vars = ['latitude', 'longitude', 'bathroomcnt', 'taxrate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Explore \n",
    "\n",
    "train_la=partitionslist[0][0]\n",
    "orange_train=partitionslist[1][0]\n",
    "ventura_train=partitionslist[2][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "\n",
    "Is there a correlation between square footage of a home and log error?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonsRsquareLogError(train_la,'structure_dollar_sqft_bin')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "\n",
    "Is there a relationship between tax rate and log error?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonsRsquareLogError(train_la,'taxrate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "\n",
    "Does log error vary by when the house was sold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingcols=['age']\n",
    "samepopdict,diffpopdict,lengthsame,lengthdiff=granulartwocombocomparison(train_la,interestingcols,target,n=100)\n",
    "\n",
    "\n",
    "\n",
    "ageandlogrelpie(lengthsame,lengthdiff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since age is actually a categorical, we explored every unique age with a sample size of greater than 100.\n",
    "\n",
    "(a conservative sample size to ensure our tests are significant).\n",
    "\n",
    " We ran the levene test then a ttest for indpendence respective to the levene test results. The net results give us a bit more detail than an ANOVA which would allow for deeper inspection.\n",
    " \n",
    " Considering an ANOVA only would answer if any of the samples differ, we can see that it is the case that our logerror overwhelmingly does not vary with age (in LA county)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4,5,6:\n",
    "\n",
    "\n",
    "Is Log error is significantly different among the counties of LA County, Orange County and Ventura County?\n",
    "\n",
    "We actually ask three seperate questions here as we compare LA to OC, LA to Ventura and Ventura to OC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threeQandA_stats_viz_counties(train_la,orange_train,ventura_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that LA and OC come from statistically different populations. However Ventura is not indepedent of LA or OC. \n",
    "\n",
    "It should be noted that the sizes of these subpopulations differ by a large degree. As we represent with the pie chart below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_train_pie(train_la,orange_train,ventura_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=partitionslist[0][1:4]\n",
    "\n",
    "train=partitionslist[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# list of variables I will cluster on. \n",
    "cluster_vars = ['scaled_latitude', 'scaled_longitude', 'age_bin']\n",
    "cluster_name = 'area_cluster'\n",
    "k_range = range(2,20)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "find_k(X[0], cluster_vars, k_range)\n",
    "\n",
    "\n",
    "\n",
    "k = 5\n",
    "# as reminders: \n",
    "cluster_vars = ['scaled_latitude', 'scaled_longitude', 'age_bin']\n",
    "cluster_name = 'area_cluster'\n",
    "\n",
    "kmeans = create_clusters(X[0], k, cluster_vars)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that k such that k equals 6,7 or 8 is my best  fit.\n",
    "\n",
    "I am not sure how to obtain that k...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)\n",
    "centroid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "X = assign_clusters(kmeans, cluster_vars, cluster_name, centroid_df,X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.DataFrame(X[0].groupby(['area_cluster', 'centroid_scaled_latitude', 'centroid_scaled_longitude', \n",
    "                           'centroid_age_bin'])['area_cluster'].count())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_vars = ['scaled_bathroomcnt', 'sqft_bin', 'acres_bin', 'bath_bed_ratio']\n",
    "cluster_name = 'size_cluster'\n",
    "k_range = range(2,20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0][cluster_vars].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "k=7\n",
    "cluster_name = 'size_cluster'\n",
    "cluster_vars = ['scaled_bathroomcnt', 'sqft_bin', 'acres_bin', 'bath_bed_ratio']\n",
    "\n",
    "# fit kmeans \n",
    "kmeans = create_clusters(X[0], k, cluster_vars)\n",
    "\n",
    "# get centroid values per variable per cluster\n",
    "centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)\n",
    "\n",
    "# get cluster assignments and append those with centroids for each X partition (train, validate, test)\n",
    "X = assign_clusters(kmeans, cluster_vars, cluster_name, centroid_df,X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train = X[0].iloc[:,0:27]\n",
    "\n",
    "xtrainlist=X_train.columns.to_list()\n",
    "# xtrainlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pd.DataFrame(X_train[X_train.size_cluster==6].groupby(['size_cluster', 'centroid_scaled_bathroomcnt', 'centroid_sqft_bin',\n",
    "                              'centroid_acres_bin', 'centroid_bath_bed_ratio'])['size_cluster'].count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laz \n",
    "### This is all me trying to figue out how to fit the clusters. \n",
    "### Still no idea. Once we get the cluster we need, look like 6 we can fit it to the model. Do you know?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grp1=X_train.groupby(['size_cluster', 'centroid_scaled_bathroomcnt', 'centroid_sqft_bin',\n",
    "#                               'centroid_acres_bin', 'centroid_bath_bed_ratio'])['size_cluster']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# list(grp1.groups.keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(grp1.groups.get((6, 0.31645721125074855, 0.5468222621184924, 0.2206822262118493, 0.708588526972728)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "# plt.scatter(y=X_train.age, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train = partitionslist[0][-3]\n",
    "\n",
    "\n",
    "# y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plt.scatter(y=y_train.logerror, x=X_train.age, c=X_train.area_cluster, alpha=.7)\n",
    "# plt.ylim(-1,1)\n",
    "# plt.xlabel('Age of Property')\n",
    "# plt.ylabel('Log Error of Zestimate')\n",
    "# plt.title(\"Do clusters reveal differences in age and error?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# sns.boxplot(y=y_train.logerror, x=X_train.area_cluster)\n",
    "# plt.ylim(-1, 1)\n",
    "# # sns.swarmplot(X_train.age_bin, y_train.logerror, hue=X_train.area_cluster)\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# # plt.scatter(y=X_train.latitude, x=X_train.longitude, c=X_train.area_cluster, alpha=.4)\n",
    "# plt.scatter(y=y_train.logerror, x=X_train.calculatedfinishedsquarefeet, c=X_train.size_cluster, alpha=.7)\n",
    "# plt.yscale('symlog')\n",
    "# plt.xlabel('Finished Square Feet')\n",
    "# plt.ylabel('Log Error of Zestimate')\n",
    "# plt.title('Is there distinction between clusters when visualizing size of the home by the error in zestimate?')\n",
    "\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt_df = X_train[['bathroomcnt', 'calculatedfinishedsquarefeet', \n",
    "                    'acres', 'bath_bed_ratio', 'size_cluster']]\n",
    "\n",
    "# sns.pairplot(data=plt_df, hue='size_cluster')\n",
    "\n",
    "\n",
    "\n",
    "# sns.scatterplot(x='bath_bed_ratio', y='calculatedfinishedsquarefeet', \n",
    "#                 data=X_train, hue='size_cluster')\n",
    "\n",
    "# update datatypes of binned values to be float\n",
    "X_train = X_train.astype({'size_cluster': 'category', 'area_cluster': 'category'})\n",
    "\n",
    "\n",
    "dummy_df = pd.get_dummies(X_train[['size_cluster','area_cluster']], dummy_na=False, drop_first=[True, True])\n",
    "\n",
    "# append dummy df cols to the original df. \n",
    "X_train = pd.concat([X_train, dummy_df], axis=1)\n",
    "\n",
    "\n",
    "# plt.scatter(X_train.longitude, X_train.latitude, c = X_train.area_cluster)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train.groupby(['area_cluster_id', 'size_cluster_id'])['structure_dollar_per_sqft']\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cols=['scaled_latitude', 'scaled_longitude', 'scaled_bathroomcnt', 'scaled_taxrate']\n",
    "dbscancols=[ 'scaled_longitude', 'scaled_bathroomcnt',  'dbscan']\n",
    "kmeanscols=[ 'scaled_longitude', 'scaled_bathroomcnt',  'kmeans']\n",
    "\n",
    "\n",
    "\n",
    "partitionslist=partitionslist_with_scaled(scaled_vars = ['latitude', 'longitude', 'bathroomcnt', 'taxrate'])\n",
    "mvp=['scaled_latitude', 'scaled_longitude', 'scaled_bathroomcnt',\n",
    "       'scaled_taxrate']\n",
    "\n",
    "train,X_train, X_validate, X_test, y_train, y_validate, y_test=partitionslist[0]\n",
    "\n",
    "#This step is to ensure we only send scaled data to the model\n",
    "MVPlist=mvpXforModels(partitionslist,mvp)\n",
    "X_train, X_validate, X_test=MVPlist[0]       \n",
    "\n",
    "rmseDF=regmodelbest(X_train, X_validate, X_test, y_train, y_validate, y_test,random=123)\n",
    "rmseDF\n",
    "LArmseDF=LATest(X_train,X_validate,X_test,y_train,y_validate,y_test)\n",
    "\n",
    "LArmseDF\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dbscan = DBSCAN(eps=0.123, min_samples = 2)\n",
    "X_train['dbscan'] = dbscan.fit_predict(X_train[cols])\n",
    "X_validate['dbscan'] = dbscan.fit_predict(X_validate[cols])\n",
    "X_test['dbscan'] = dbscan.fit_predict(X_test[cols])\n",
    "# kmeans_degree6 = pf6.transform(kmeans_degree6)\n",
    "\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "X_train['kmeans'] = kmeans.fit_predict(X_train[cols])\n",
    "X_validate['kmeans'] = kmeans.fit_predict(X_validate[cols])\n",
    "X_test['kmeans'] = kmeans.fit_predict(X_test[cols])\n",
    "# dbscan_degree6 = pf6.transform(dbscan_degree6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dbclusterRSME=LATest(X_train[dbscancols],X_validate[dbscancols],X_test[dbscancols],y_train,y_validate,y_test)\n",
    "\n",
    "dbclusterRSME\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "KmeansclusterRSME=LATest(X_train[kmeanscols],X_validate[kmeanscols],X_test[kmeanscols],y_train,y_validate,y_test)\n",
    "\n",
    "KmeansclusterRSME\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
